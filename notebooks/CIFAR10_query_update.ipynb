{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# visualizing specific queries\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd \n",
    "import json \n",
    "import copy \n",
    "import pickle \n",
    "import os \n",
    "import sys\n",
    "import copy\n",
    "import umap\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path.append('../py_scripts')\n",
    "from py_scripts import LightningDataModule, get_params_net_dataloader\n",
    "import glob\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from diffusion_utils import *\n",
    "\n",
    "# DONT NEED TO USE GPU HERE\n",
    "\n",
    "use_gpu = False\n",
    "\n",
    "if use_gpu: \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else: \n",
    "    device=\"cpu\"\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "bs = 10\n",
    "\n",
    "nper_row = 25\n",
    "max_images = nper_row**2\n",
    "\n",
    "show_receptive_fields = False\n",
    "save_value_fields = False\n",
    "\n",
    "min_max_scale = False \n",
    "peak_scale = True\n",
    "\n",
    "save_name_base = \"peak_scale_625\"\n",
    "\n",
    "li_model_templates = {\n",
    "    \"19000epochs\":'Another6KEpochs_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1',\n",
    "    \"9000epochs\":'ReconCIFAR10Long_EvenMore_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1',\n",
    "    \"3000epochs\":\"ReconCIFAR10Long_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "}\n",
    "# need to iterate through these. \n",
    "\n",
    "#LowerLR\n",
    "model_template = \"Another6KEpochs_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"ReconCIFAR10Long_EvenMore_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"InhibCircuitSimple_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"Sigmoid_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"GELU_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"Interpretable_NoCosine_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"#Interpretable_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\"\n",
    "#\"_ffnCIFAR10_w_Projections_Adam_lr0.0001_datas=None_10000Neurons_projM=True_nlayers1\"\n",
    "#\"_ffnRaw_CIFAR10_Adam_lr0.0001_datas=None_10000Neurons_projM=False_nlayers1\" #\"_ffnRaw_CIFAR10_Adam_lr1e-05_datas=None_10000Neurons_projM=False_nlayers1\"#\"_ffnBaseline_Adam_lr0.0001_datas=None_1steps_10000Neurons_projM=False_nlayers1\"\n",
    "\n",
    "use_CIFAR10 = True\n",
    "\n",
    "model_prefixes = [0.0,0.05,0.1,0.3,0.8,1.5, 3.0, 10.0] #['0.0001', '0.00001', '0.000001', '0.0000001', 0.0]\n",
    "#[0.0,0.05,0.1,0.3,0.8,1.5, 3.0, 10.0]\n",
    "#[\"100N\",\"1_000N\",\"10_000N\",\"100_000N\"]\n",
    "\n",
    "dataset_path=\"../data/\"\n",
    "save_dir = \"../../scratch_link/Foundational-SDM/data/CachedLatents/\"\n",
    "extra = {\"use_wandb\":False,\"classification\":False, \"non_relu_act_threshold\":0.0001}\n",
    "\n",
    "num_queries = 3\n",
    "only_all_receptives = True\n",
    "\n",
    "if \"CIFAR10\" in model_template or use_CIFAR10: \n",
    "    latent, labels = torch.load('../data/CIFAR10/all_data_train.pt')\n",
    "    latent = latent.flatten(start_dim=1 )\n",
    "    if latent.dtype is torch.uint8:#\"/ImageNet32/\" in self.dataset_path or \"/CIFAR10/\" in self.dataset_path:\n",
    "            latent = latent.type(torch.float)/255\n",
    "else: \n",
    "\n",
    "    latent, labels = torch.load('../data/CachedOutputs/ConvMixerWTransforms_ImgNet32_CIFAR10/all_data_train.pt')\n",
    "\n",
    "q_rand_inds = np.random.choice(len(latent), num_queries, replace=False)\n",
    "\n",
    "for template_details, model_template in li_model_templates.items():\n",
    "\n",
    "    fig_save_name = f\"{template_details}_{save_name_base}\"\n",
    "\n",
    "    for run_ind, run in enumerate(model_prefixes): \n",
    "        print(\"Noise amount:\", run)\n",
    "\n",
    "        model, params = load_model(f\"{run}{model_template}\", dataset_path, save_dir, device, extra_extras=extra)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            q = model.run_model_till_noise( latent[q_rand_inds].to(device) )\n",
    "            q_act_neurons = model.run_model_till_neuron_activations(q, apply_noise=False)\n",
    "            x_recons = model.run_after_noise(q)\n",
    "            q, q_act_neurons = q.cpu() , q_act_neurons.cpu() \n",
    "\n",
    "        xas = model.X_a().weight.cpu().detach()\n",
    "        xvs = model.X_v().cpu().detach()\n",
    "        #if not only_all_receptives:\n",
    "\n",
    "        if run_ind==0 or not only_all_receptives:\n",
    "            gridshow( latent[q_rand_inds].view(num_queries, 3,32,32), title=f\"Original images\", save_name=f\"query_activated_recpt_fields/{fig_save_name}_Queries\" )\n",
    "\n",
    "        if not only_all_receptives:\n",
    "        \n",
    "            gridshow( q.view(num_queries, 3,32,32), title=f\"Noisy images\" )\n",
    "            gridshow( x_recons.view(num_queries, 3,32,32), title=f\"Reconstruction | Noise amount={run}\" )\n",
    "\n",
    "        num_active = (q_act_neurons>0.0).sum(1)\n",
    "        print( \"====== number of neurons active for each query\", num_active)\n",
    "\n",
    "        act_vals, act_inds = torch.sort(q_act_neurons, dim=1, descending=True)\n",
    "\n",
    "\n",
    "        dists = cosine_sim_matrices(model.X_a().weight.detach(), q).T\n",
    "        dist_vals, dist_inds = torch.topk(dists, 5, dim=1)#.max(dim=0) # what neuron is closest to each query. \n",
    "        print(\"dist inds\", dist_inds.shape )\n",
    "\n",
    "        for qind in range(num_queries):\n",
    "\n",
    "            if not only_all_receptives:\n",
    "                gridshow( latent[q_rand_inds[qind]].view(1, 3,32,32), title=f\"Target Pattern\" )\n",
    "                gridshow( q[qind].view(1, 3,32,32), title=f\"Actual Query\" )\n",
    "                gridshow( xas[dist_inds[qind]], title=f\"Top 5 Neurons with closest cosine similarity to the query\", use_mm_scale=min_max_scale, use_peak_scale=peak_scale )\n",
    "\n",
    "            #closest cosine sim\n",
    "\n",
    "            print('activities', act_vals[qind][:num_active[qind]][:max_images], )\n",
    "\n",
    "            if len(xas[act_inds[qind][:num_active[qind]]])>max_images:\n",
    "                print(f\"MORE THAN {max_images} max_images being used.\")\n",
    "            gridshow( xas[act_inds[qind][:num_active[qind]]][:max_images], title=f\"Keys | Sorted by activation value | Noise amount={run}\", use_mm_scale=min_max_scale, use_peak_scale=peak_scale, nrow=nper_row, save_name=f\"query_activated_recpt_fields/{fig_save_name}_keys__{run}_{qind}\", show_plot= show_receptive_fields)\n",
    "            if not params.classification and save_value_fields:\n",
    "                gridshow( xvs[act_inds[qind][:num_active[qind]]][:max_images], title=f\"Values | Sorted by activation value | Noise amount={run}\", use_mm_scale=min_max_scale, use_peak_scale=peak_scale, nrow=nper_row, save_name=f\"query_activated_recpt_fields/{fig_save_name}_values_{run}_{qind}\", show_plot=show_receptive_fields )\n",
    "\n",
    "            if not only_all_receptives:\n",
    "\n",
    "                # relationship between overall neuron activity and what is active for random queries. \n",
    "                neuron_active_summer = get_active_neurons(model, latent, device, params.nneurons[0])\n",
    "\n",
    "                plt.scatter(neuron_active_summer, q_act_neurons[qind], label=\"all neurons\", alpha=0.2)\n",
    "                plt.scatter(neuron_active_summer[ act_inds[qind][:num_active[qind]] ], act_vals[qind][:num_active[qind]], label=\"active neurons\", alpha=0.2)\n",
    "                plt.xlabel(\"Overall Activity\")\n",
    "                plt.ylabel(\"Activity for this neuron\")\n",
    "                plt.legend()\n",
    "                plt.title(\"Active Neurons for this Query as a function of their overall activity\")\n",
    "                plt.show()\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "q.shape , q_act_neurons.shape "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.hist( (q_act_neurons>0).sum(1) )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "plt.hist(q_act_neurons[0], bins=50 )\n",
    "plt.show() "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "q_ind = 0\n",
    "k=10\n",
    "\n",
    "vals, inds = torch.topk(q_act_neurons[q_ind], k)\n",
    "\n",
    "\n",
    "gridshow(latent[q_rand_inds][q_ind].view(3,32,32))\n",
    "gridshow(q[q_ind].view(1, 3,32,32))\n",
    "gridshow(x_recons[q_ind].view(1, 3,32,32))\n",
    "plt.show()\n",
    "gridshow( min_max_scale(xas[inds]).view(k,3,32,32 ))\n",
    "\n",
    "gridshow( min_max_scale(xvs[inds]).view(k,3,32,32 ))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ab95d2732a92093d9ea778b6aa24b3919e4e23eea354fb78837ca91d80ad5a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
